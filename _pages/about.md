---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a PhD student at the Hong Kong University of Science and Technology (HKUST), advised by [Prof. Fangzhen Lin](https://cse.hkust.edu.hk/~flin/), and in close collaboration with [Prof. Wenhu Chen](https://wenhuchen.github.io/) at the University of Waterloo.  I am fortunate to be supported by the **Hong Kong PhD Fellowship Scheme (HKPFS)**, with only 300 awardees across Hong Kong each year.  

My research focuses on <u>Large Language Models (LLMs) and Vision-Language Models (VLMs), Reasoning, RL and agents</u>. My recent work includes developing RL-based approaches to enhance VLM and LLM reasoning, as seen in projects like [VL-Rethinker](https://tiger-ai-lab.github.io/VL-Rethinker/), [Autocode](https://arxiv.org/abs/2502.00691), [ACECoder](https://arxiv.org/abs/2502.01718), and [HTL](https://arxiv.org/abs/2402.15729). For a comprehensive list of my publications, please visit [my Google Scholar](https://scholar.google.ca/citations?user=V96YGIMAAAAJ&hl=en).

Prior to joining HKUST, I worked as a Researcher at INF Technology, advised by [Dr. Wei Chu](https://weichu.github.io/), and as an AI Engineer at Alibaba, under the guidance of [Dr. Chao Du](https://duchao0726.github.io/). These experiences allowed me to deepen my expertise in AI and machine learning while contributing to impactful industry projects.

Prior to these working experiences, I was recognized as one of the **Outstanding Graduates of Shanghai** (top 1% province-wide) when studying at ShanghaiTech, and I was awarded the prestigious **National Scholarship** (top 0.2% nation-wide) at Wuhan University in 2017.

<!-- 
I have a broad research experience in machine learning, including
Reinforcement Learning, Variational Bayes, Vison and Language. <ins>Currently, I am super excited about research on Generative AI, and I am looking for opportunities / research collaborations on relevant topics.</ins> For more details, please check out my [CV](https://raw.githubusercontent.com/HazekiahWon/helios2/master/assets/Research_CV.pdf). -->

Notice
======
<span style="color: red;">I am actively seeking research collaboration and research opportunities in VLMs, RL and agents</span>,  preferably remote.
Let's make real impacts to both the industry and the academia! 



News
======
2025.05<span style="padding-left: 20px;"></span>We release [Pixel Reasoner](https://tiger-ai-lab.github.io/Pixel-Reasoner/), which studies the key reasoning paradigm behind o3/o4-mini. We introduce Pixel-Space Reasoning for the first time, and identify a critical learning trap when cultivating this novel reasoning capability.

2025.05<span style="padding-left: 20px;"></span>Four papers accepted to ACL 2024! Please Check [Autocode](https://arxiv.org/abs/2502.00691), [ACECoder](https://arxiv.org/abs/2502.01718), [SynMed](https://arxiv.org/abs/2410.13523), [Argus](https://arxiv.org/abs/2406.07146).

2025.04<span style="padding-left: 20px;"></span>We introduce [VL-Rethinker](https://tiger-ai-lab.github.io/VL-Rethinker/), which explores how to incentivize deliberate thinking in VLMs. It achieves superior results on a diverse collection of multimodal benchmarks.

2025.03<span style="padding-left: 20px;"></span>We release a new diffusion quantization method: [TR-DQ](https://arxiv.org/pdf/2503.06564).

2025.02<span style="padding-left: 20px;"></span>We release [Autocode](https://arxiv.org/abs/2502.00691) on metacognitive tool-use LLMs for math, and [ACECoder](https://arxiv.org/abs/2502.01718) for large-scale test-case synthesis for coder RL training.

2025.01<span style="padding-left: 20px;"></span>[RenderWorld](https://arxiv.org/abs/2409.11356) accepted to ICRA 2025. It studied 3D world models. Congrats to Yihua!

2024.10<span style="padding-left: 20px;"></span>[V-PETL Benchmark](https://proceedings.neurips.cc/paper_files/paper/2024/file/935de67d1a033fd517cb49d192b5c008-Paper-Datasets_and_Benchmarks_Track.pdf) accepted to NeurIPS 2025.

2024.08<span style="padding-left: 20px;"></span>[HTL](https://arxiv.org/abs/2402.15729) accepted to EMNLP 2025. It studied tool-integrated reasoning for math reasoning.


