---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a PhD student at the Hong Kong University of Science and Technology (HKUST), advised by [Prof. Fangzhen Lin](https://cse.hkust.edu.hk/~flin/), and in close collaboration with [Prof. Wenhu Chen](https://wenhuchen.github.io/) at the University of Waterloo and [Ge Zhang](https://scholar.google.com/citations?user=qyTrq4kAAAAJ&hl=zh-CN) at ByteDance Seed.  I am fortunate to be supported by the **Hong Kong PhD Fellowship Scheme (HKPFS)**, with only 300 awardees across Hong Kong each year.  

My research focuses on <u>Large Language Models (LLMs) and Vision-Language Models (VLMs), Reasoning, RL and agents</u>. My recent work includes developing RL-based approaches to enhance VLM and LLM reasoning, as seen in projects like [REverse-Engineered Reasoning (REER)](https://haozheh3.github.io/REER_DeepWriter/), [Hierarchical-Reasoner](https://www.arxiv.org/abs/2509.03646), [Pixel-Reasoner](https://tiger-ai-lab.github.io/Pixel-Reasoner/), [VL-Rethinker](https://tiger-ai-lab.github.io/VL-Rethinker/). For a comprehensive list of my publications, please visit [my Google Scholar](https://scholar.google.ca/citations?user=V96YGIMAAAAJ&hl=en).

Prior to joining HKUST, I worked as a Research Engineer at Alibaba, under the guidance of [Dr. Chao Du](https://duchao0726.github.io/). These experiences allowed me to deepen my expertise in AI and machine learning while contributing to impactful industry projects.

Prior to these working experiences, I was recognized as one of the **Outstanding Graduates of Shanghai** (top 1% province-wide) when studying at ShanghaiTech, and I was awarded the prestigious **National Scholarship** (top 0.2% nation-wide) at Wuhan University in 2017.

<!-- 
I have a broad research experience in machine learning, including
Reinforcement Learning, Variational Bayes, Vison and Language. <ins>Currently, I am super excited about research on Generative AI, and I am looking for opportunities / research collaborations on relevant topics.</ins> For more details, please check out my [CV](https://raw.githubusercontent.com/HazekiahWon/helios2/master/assets/Research_CV.pdf). -->

Notice
======
<span style="color: red;">I am actively seeking research collaboration and research opportunities in VLMs, RL and agents</span>,  preferably remote.
Let's make real impacts to both the industry and the academia! 



News
======
2025.09<span style="padding-left: 20px;"></span>We release [REverse-Engineered Reasoning (REER)](https://haozheh3.github.io/REER_DeepWriter/) for Open-Ended Generation. This provides a third path for producing high-quality deep reasoning without RL or costly distillation.

2025.09<span style="padding-left: 20px;"></span>We release [Hierarchical-Reasoner](https://www.arxiv.org/abs/2509.03646). We analyze the training dynamics across six text and vision-language models, identifying an **emergent hierarchical reasoning through RL that underpins boost in math reasoning**. This reasoning hierarchy parallels the human's cognitive model, provides direct explanations for opaque observations of "aha moments", "length scaling", and **points out the flaws in token entropy for tracking exploration in RL**.

2025.08<span style="padding-left: 20px;"></span>We release [VerlTool](https://arxiv.org/abs/2509.01055v1), seamlessly integrating tool-use with the widely adopted VeRL framework.
2025.06<span style="padding-left: 20px;"></span>We release [AlphaMed](https://cheliu-computation.github.io/AlphaM/), a minimalist zero-RL approach to medical reasoning.

2025.06<span style="padding-left: 20px;"></span>We release [Infinity-Parser](https://arxiv.org/abs/2506.03197), with a comprehensive Doc-Parsing dataset, Infinity-Doc-55K, and a strong Doc-Parser through layout-aware RL.

2025.05<span style="padding-left: 20px;"></span>We release [Pixel Reasoner](https://tiger-ai-lab.github.io/Pixel-Reasoner/), which studies the key reasoning paradigm behind o3/o4-mini. We introduce Pixel-Space Reasoning for the first time, and identify a critical learning trap when cultivating this novel reasoning capability.

2025.05<span style="padding-left: 20px;"></span>Four papers accepted to <b>ACL 2025</b>! Please Check [Autocode](https://arxiv.org/abs/2502.00691), [ACECoder](https://arxiv.org/abs/2502.01718), [SynMed](https://arxiv.org/abs/2410.13523), [Argus](https://arxiv.org/abs/2406.07146).

2025.04<span style="padding-left: 20px;"></span>We introduce [VL-Rethinker](https://tiger-ai-lab.github.io/VL-Rethinker/), which explores how to incentivize deliberate thinking in VLMs. It achieves superior results on a diverse collection of multimodal benchmarks.

2025.03<span style="padding-left: 20px;"></span>We release a new diffusion quantization method: [TR-DQ](https://arxiv.org/pdf/2503.06564).

2025.02<span style="padding-left: 20px;"></span>We release [Autocode](https://arxiv.org/abs/2502.00691) on metacognitive tool-use LLMs for math, and [ACECoder](https://arxiv.org/abs/2502.01718) for large-scale test-case synthesis for coder RL training.

2025.01<span style="padding-left: 20px;"></span>[RenderWorld](https://arxiv.org/abs/2409.11356) accepted to <b>ICRA 2025</b>. It studied 3D world models. Congrats to Yihua!

2024.10<span style="padding-left: 20px;"></span>[V-PETL Benchmark](https://proceedings.neurips.cc/paper_files/paper/2024/file/935de67d1a033fd517cb49d192b5c008-Paper-Datasets_and_Benchmarks_Track.pdf) accepted to <b>NeurIPS 2024</b>.

<!-- 2024.08<span style="padding-left: 20px;"></span>[HTL](https://arxiv.org/abs/2402.15729) accepted to <b>EMNLP 2024</b>. It studied tool-integrated reasoning for math reasoning. -->


